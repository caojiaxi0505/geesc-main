\section{introduction}
Large Language Models (LLMs) have demonstrated emergent reasoning capabilities that are pivotal to their success in complex, multi-step tasks \citep{NEURIPS2022_9d560961}. Techniques such as Chain-of-Thought (CoT) prompting, which guide models to articulate intermediate reasoning steps, have become standard practice for eliciting more structured and accurate problem-solving. However, the reasoning chains produced by LLMs are not inherently reliable. They can be susceptible to factual hallucinations, logical fallacies, and an over-reliance on superficial semantic associations, leading to outputs that are plausible but incorrect \citep{han-etal-2025-concept, lobo-etal-2025-impact}. This unreliability of the reasoning chains undermines the trustworthiness of LLMs, especially in high-stakes applications.

To mitigate this, Self-Consistency (SC) was introduced as a robust decoding strategy \citep{wang2023selfconsistency}. By sampling a diverse set of reasoning paths and taking a majority vote on the final answers, SC smooths over the errors of individual generations. Despite its effectiveness, the main drawback of SC is that it relies on making many repeated attempts and then voting on the result, which uses a lot of computing resources. It applies a monolithic, fixed-budget sampling strategy, generating a large number of full-length paths for every problem, irrespective of its inherent difficulty. This means simple problems needlessly consume as much compute as complex ones, while a significant portion of the generated paths are semantically redundant, logically flawed, or factually ungrounded from the outset \citep{lee-etal-2025-generating}.

Existing approaches to enhance reasoning often involve constructing more elaborate search structures, such as trees or graphs, which allow for exploration and backtracking \citep{yao2023tree, chi-etal-2025-thoughtsculpt}. While powerful, these methods can exacerbate the efficiency problem. The key challenge is to preserve the robustness of multi-path exploration while curbing combinatorial growth through informed pruning and adaptive compute allocation.

In this paper, we propose Grounded Early-Exit Self-Consistency (GEESC), a framework that addresses the inefficiency of Self-Consistency through a dual optimization of path quality and quantity. GEESC integrates a retrieval-augmented verification and correction mechanism at the prefix stage of reasoning. Instead of generating complete CoT paths, it first produces short, initial reasoning steps. Each prefix is then subjected to a rapid, dual-criterion evaluation: a Retrieval-Augmented Generation (RAG) module verifies factual claims, and a perplexity score assesses semantic coherence. Prefixes that contradict evidence or are incoherent are immediately pruned.

Crucially, this early-exit mechanism provides a powerful signal for an adaptive reasoning budget. If the first few generated prefixes are of high quality and pass the verification filter, it suggests the problem is likely straightforward, allowing the process to terminate early with a confident answer. Conversely, if initial paths are frequently pruned, it indicates a more challenging problem, justifying the allocation of additional computational effort to generate more diverse paths. This dual optimization—improving the quality of each path (intra-path) and dynamically adjusting the number of paths (inter-path)—drastically reduces computational waste. For promising paths with minor factual errors, GEESC also leverages the retrieved information for active correction.

Our contributions are threefold:
\begin{itemize}
\item We identify and formalize the dual inefficiencies of standard Self-Consistency: the generation of full-length, factually ungrounded paths and the application of a rigid, fixed computational budget to all problems.
\item We propose Grounded Early-Exit Self-Consistency (GEESC), a novel framework that addresses these issues by using a retrieval-augmented filter to prune and correct reasoning prefixes. This core mechanism enables an adaptive sampling strategy, which dynamically allocates more computational resources to more challenging problems.
\item We demonstrate through extensive experiments that GEESC significantly improves both computational efficiency and reasoning accuracy over strong baselines, producing more reliable and factually grounded outputs.
\end{itemize}